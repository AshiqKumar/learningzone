# Deep Learning Theory - Neural Networks and Modern AI

## üß† Neural Network Fundamentals

### 1. Basic Neural Network Theory

#### 1.1 Perceptron Model

**Mathematical Representation**:
```
y = f(Œ£(w·µ¢x·µ¢) + b)
    i=1

Where:
- x·µ¢: input features
- w·µ¢: weights
- b: bias term
- f: activation function
```

**Activation Functions**:

*Sigmoid*:
```
œÉ(x) = 1 / (1 + e^(-x))
œÉ'(x) = œÉ(x)(1 - œÉ(x))
```

*ReLU (Rectified Linear Unit)*:
```
ReLU(x) = max(0, x)
ReLU'(x) = {1 if x > 0, 0 if x ‚â§ 0}
```

*Tanh*:
```
tanh(x) = (e^x - e^(-x)) / (e^x + e^(-x))
tanh'(x) = 1 - tanh¬≤(x)
```

*Leaky ReLU*:
```
LeakyReLU(x) = {x if x > 0, Œ±x if x ‚â§ 0}
Where Œ± ‚àà (0, 1), typically 0.01
```

#### 1.2 Multi-layer Perceptron (MLP)

**Forward Propagation**:
```
Layer l: a^(l) = f^(l)(W^(l)a^(l-1) + b^(l))

Where:
- a^(l): activation at layer l
- W^(l): weight matrix for layer l
- b^(l): bias vector for layer l
- f^(l): activation function for layer l
```

**Universal Approximation Theorem**:
A single hidden layer MLP with finite neurons can approximate any continuous function on a compact set to arbitrary accuracy.

### 2. Backpropagation Algorithm

#### 2.1 Mathematical Derivation

**Cost Function** (Mean Squared Error):
```
J(W,b) = (1/2m) Œ£ ||y^(i) - ≈∑^(i)||¬≤
         i=1

Where m is number of training examples
```

**Chain Rule Application**:
```
‚àÇJ/‚àÇW^(l) = ‚àÇJ/‚àÇz^(l) √ó ‚àÇz^(l)/‚àÇW^(l)
‚àÇJ/‚àÇb^(l) = ‚àÇJ/‚àÇz^(l) √ó ‚àÇz^(l)/‚àÇb^(l)

Where z^(l) = W^(l)a^(l-1) + b^(l)
```

**Error Propagation**:
```
Œ¥^(L) = ‚àá_a J ‚äô œÉ'(z^(L))           (output layer)
Œ¥^(l) = ((W^(l+1))^T Œ¥^(l+1)) ‚äô œÉ'(z^(l))  (hidden layers)

Where ‚äô is element-wise multiplication
```

**Weight Updates**:
```
W^(l) = W^(l) - Œ∑ √ó Œ¥^(l) √ó (a^(l-1))^T
b^(l) = b^(l) - Œ∑ √ó Œ¥^(l)

Where Œ∑ is learning rate
```

### 3. Convolutional Neural Networks (CNNs)

#### 3.1 Convolution Operation

**2D Convolution**:
```
(I * K)(i,j) = Œ£ Œ£ I(m,n) √ó K(i-m, j-n)
               m n

Feature map: Y_{i,j} = œÉ(Œ£ Œ£ X_{i+m,j+n} √ó W_{m,n} + b)
                        m n
```

**Output Size Calculation**:
```
Output_height = (Input_height + 2√óPadding - Kernel_height) / Stride + 1
Output_width = (Input_width + 2√óPadding - Kernel_width) / Stride + 1
```

**Parameter Count**:
```
Conv Layer Parameters = (K_h √ó K_w √ó C_in + 1) √ó C_out

Where:
- K_h, K_w: kernel dimensions
- C_in: input channels
- C_out: output channels
- +1: bias term
```

#### 3.2 Pooling Operations

**Max Pooling**:
```
MaxPool(X)_{i,j} = max{X_{i√ós+m, j√ós+n} | 0 ‚â§ m,n < k}

Where:
- k: pooling kernel size
- s: stride
```

**Average Pooling**:
```
AvgPool(X)_{i,j} = (1/k¬≤) √ó Œ£ Œ£ X_{i√ós+m, j√ós+n}
                            m=0 n=0
```

**Global Average Pooling**:
```
GAP(X) = (1/HW) √ó Œ£ Œ£ X_{i,j}
                  i=1 j=1
```

#### 3.3 CNN Architectures

**LeNet-5** (LeCun et al., 1998):
```
Input(32√ó32) ‚Üí Conv(6@5√ó5) ‚Üí Pool(2√ó2) ‚Üí Conv(16@5√ó5) ‚Üí Pool(2√ó2) ‚Üí FC(120) ‚Üí FC(84) ‚Üí FC(10)
```

**AlexNet** (Krizhevsky et al., 2012):
```
Input(224√ó224√ó3) ‚Üí Conv(96@11√ó11,s=4) ‚Üí Pool ‚Üí Conv(256@5√ó5) ‚Üí Pool ‚Üí 
Conv(384@3√ó3) ‚Üí Conv(384@3√ó3) ‚Üí Conv(256@3√ó3) ‚Üí Pool ‚Üí FC(4096) ‚Üí FC(4096) ‚Üí FC(1000)
```

**ResNet** (He et al., 2016):
- Skip connections: y = F(x) + x
- Solves vanishing gradient problem
- Identity mapping for gradient flow

### 4. Advanced CNN Concepts

#### 4.1 Batch Normalization

**Normalization**:
```
Œº = (1/m) √ó Œ£ x·µ¢          (batch mean)
        i=1

œÉ¬≤ = (1/m) √ó Œ£ (x·µ¢ - Œº)¬≤  (batch variance)
         i=1

xÃÇ·µ¢ = (x·µ¢ - Œº) / ‚àö(œÉ¬≤ + Œµ)  (normalized)

y·µ¢ = Œ≥xÃÇ·µ¢ + Œ≤              (scaled and shifted)
```

**Benefits**:
- Reduces internal covariate shift
- Allows higher learning rates
- Acts as regularization

#### 4.2 Dropout Regularization

**Training Phase**:
```
y·µ¢ = {x·µ¢/p with probability p
     {0     with probability 1-p
```

**Test Phase**:
```
y·µ¢ = x·µ¢  (no dropout, scaling handled by training)
```

**Mathematical Analysis**:
- Reduces overfitting
- Approximates model averaging
- Forces redundant representations

### 5. Object Detection Theory

#### 5.1 YOLO (You Only Look Once)

**Grid-based Detection**:
- Divide image into S√óS grid
- Each cell predicts B bounding boxes
- Each box: (x, y, w, h, confidence)
- Each cell: C class probabilities

**Mathematical Formulation**:
```
Bounding Box: (b‚Çì, b_y, b·µ®, b_h)
b‚Çì = œÉ(t‚Çì) + c‚Çì    (center x relative to cell)
b_y = œÉ(t_y) + c_y  (center y relative to cell)
b·µ® = p·µ® √ó e^(t·µ®)    (width relative to anchor)
b_h = p_h √ó e^(t_h)  (height relative to anchor)

Where œÉ is sigmoid, (c‚Çì, c_y) is cell coordinates
```

**Loss Function**:
```
L = Œª_coord Œ£ Œ£ ùüô·µ¢‚±º·µí·µá ≤[(x·µ¢ - xÃÇ·µ¢)¬≤ + (y·µ¢ - ≈∑·µ¢)¬≤]
    + Œª_coord Œ£ Œ£ ùüô·µ¢‚±º·µí·µá ≤[(‚àöw·µ¢ - ‚àö≈µ·µ¢)¬≤ + (‚àöh·µ¢ - ‚àöƒ•·µ¢)¬≤]
    + Œ£ Œ£ ùüô·µ¢‚±º·µí·µá ≤(C·µ¢ - ƒà·µ¢)¬≤
    + Œª_noobj Œ£ Œ£ ùüô·µ¢‚±º‚Åø·µí·µí·µá ≤(C·µ¢ - ƒà·µ¢)¬≤
    + Œ£ ùüô·µ¢·µí·µá ≤ Œ£ (p·µ¢(c) - pÃÇ·µ¢(c))¬≤

Where ùüô·µ¢‚±º·µí·µá ≤ = 1 if object appears in cell i,j
```

#### 5.2 Non-Maximum Suppression (NMS)

**Algorithm**:
1. Sort detections by confidence score
2. Select highest scoring detection
3. Remove detections with IoU > threshold
4. Repeat until no detections remain

**Intersection over Union (IoU)**:
```
IoU = Area(Box‚ÇÅ ‚à© Box‚ÇÇ) / Area(Box‚ÇÅ ‚à™ Box‚ÇÇ)

Area(A ‚à© B) = max(0, min(x‚ÇÅ·¥¨, x‚ÇÅ·¥Æ) - max(x‚ÇÄ·¥¨, x‚ÇÄ·¥Æ)) √ó 
              max(0, min(y‚ÇÅ·¥¨, y‚ÇÅ·¥Æ) - max(y‚ÇÄ·¥¨, y‚ÇÄ·¥Æ))
```

### 6. Face Recognition Deep Learning

#### 6.1 Siamese Networks

**Architecture**:
```
Twin networks with shared weights:
f(x‚ÇÅ) and f(x‚ÇÇ) ‚Üí distance measure ‚Üí similarity score
```

**Contrastive Loss**:
```
L = ¬Ω Œ£ [y √ó D¬≤ + (1-y) √ó max(0, m - D)¬≤]
Where:
- y = 1 if same identity, 0 if different
- D = ||f(x‚ÇÅ) - f(x‚ÇÇ)||‚ÇÇ
- m = margin parameter
```

#### 6.2 Triplet Loss

**Triplet Selection**:
- Anchor: reference image
- Positive: same identity as anchor
- Negative: different identity from anchor

**Loss Function**:
```
L = Œ£ max(0, ||f(a) - f(p)||¬≤ - ||f(a) - f(n)||¬≤ + Œ±)

Where:
- a: anchor
- p: positive
- n: negative
- Œ±: margin
```

#### 6.3 ArcFace Loss

**Angular Margin**:
```
L = -log(e^(s¬∑cos(Œ∏_y·µ¢ + m)) / (e^(s¬∑cos(Œ∏_y·µ¢ + m)) + Œ£ e^(s¬∑cos(Œ∏‚±º))))
                                                      j‚â†y·µ¢

Where:
- s: scale parameter
- m: angular margin
- Œ∏_y·µ¢: angle between feature and weight
```

### 7. Optimization Theory

#### 7.1 Gradient Descent Variants

**Stochastic Gradient Descent (SGD)**:
```
Œ∏ = Œ∏ - Œ∑ √ó ‚àáŒ∏ J(Œ∏; x^(i), y^(i))
```

**Mini-batch Gradient Descent**:
```
Œ∏ = Œ∏ - Œ∑ √ó (1/B) Œ£ ‚àáŒ∏ J(Œ∏; x^(i), y^(i))
                  i‚ààB
```

**Momentum**:
```
v_t = Œ≥v_{t-1} + Œ∑‚àáŒ∏ J(Œ∏)
Œ∏ = Œ∏ - v_t

Where Œ≥ ‚àà [0,1] is momentum coefficient
```

#### 7.2 Adaptive Learning Rate Methods

**AdaGrad**:
```
G_t = G_{t-1} + (‚àáŒ∏ J(Œ∏))¬≤
Œ∏ = Œ∏ - (Œ∑/‚àö(G_t + Œµ)) √ó ‚àáŒ∏ J(Œ∏)
```

**Adam** (Adaptive Moment Estimation):
```
m_t = Œ≤‚ÇÅm_{t-1} + (1-Œ≤‚ÇÅ)‚àáŒ∏ J(Œ∏)       (first moment)
v_t = Œ≤‚ÇÇv_{t-1} + (1-Œ≤‚ÇÇ)(‚àáŒ∏ J(Œ∏))¬≤    (second moment)

mÃÇ_t = m_t / (1-Œ≤‚ÇÅ^t)    (bias correction)
vÃÇ_t = v_t / (1-Œ≤‚ÇÇ^t)    (bias correction)

Œ∏ = Œ∏ - Œ∑ √ó mÃÇ_t / (‚àövÃÇ_t + Œµ)
```

**Parameters**:
- Œ≤‚ÇÅ = 0.9 (first moment decay)
- Œ≤‚ÇÇ = 0.999 (second moment decay)
- Œµ = 1e-8 (small constant)

### 8. Regularization Techniques

#### 8.1 L1 and L2 Regularization

**L1 Regularization (Lasso)**:
```
J_reg = J + Œª Œ£ |w·µ¢|
           i

Gradient: ‚àÇJ_reg/‚àÇw = ‚àÇJ/‚àÇw + Œª √ó sign(w)
```

**L2 Regularization (Ridge)**:
```
J_reg = J + Œª Œ£ w·µ¢¬≤
           i

Gradient: ‚àÇJ_reg/‚àÇw = ‚àÇJ/‚àÇw + 2Œªw
```

**Elastic Net**:
```
J_reg = J + Œª‚ÇÅ Œ£ |w·µ¢| + Œª‚ÇÇ Œ£ w·µ¢¬≤
           i        i
```

#### 8.2 Early Stopping

**Validation-based Stopping**:
1. Monitor validation loss during training
2. Stop when validation loss stops decreasing
3. Restore weights from best validation epoch

**Mathematical Criterion**:
```
Stop if: val_loss(epoch) > val_loss(epoch - patience)
```

### 9. Loss Functions

#### 9.1 Classification Losses

**Cross-Entropy Loss**:
```
L = -Œ£ y·µ¢ log(≈∑·µ¢)
    i

For binary: L = -[y log(≈∑) + (1-y) log(1-≈∑)]
```

**Focal Loss** (for imbalanced datasets):
```
FL(p_t) = -Œ±_t(1-p_t)^Œ≥ log(p_t)

Where:
- Œ±_t: weighting factor
- Œ≥: focusing parameter
- p_t: predicted probability for true class
```

#### 9.2 Regression Losses

**Mean Squared Error (MSE)**:
```
MSE = (1/n) Œ£ (y·µ¢ - ≈∑·µ¢)¬≤
           i
```

**Mean Absolute Error (MAE)**:
```
MAE = (1/n) Œ£ |y·µ¢ - ≈∑·µ¢|
           i
```

**Huber Loss** (robust to outliers):
```
L_Œ¥(y, ≈∑) = {¬Ω(y - ≈∑)¬≤           if |y - ≈∑| ‚â§ Œ¥
           {Œ¥|y - ≈∑| - ¬ΩŒ¥¬≤       otherwise
```

### 10. Transfer Learning Theory

#### 10.1 Feature Extraction vs Fine-tuning

**Feature Extraction**:
- Freeze pre-trained layers
- Train only classifier layers
- Fast training, less data required

**Fine-tuning**:
- Initialize with pre-trained weights
- Train all layers with small learning rate
- Better performance, requires more data

#### 10.2 Domain Adaptation

**Mathematical Framework**:
```
Source domain: DS = {(xÀ¢·µ¢, yÀ¢·µ¢)}‚ÅøÀ¢·µ¢‚Çå‚ÇÅ
Target domain: DT = {x·µó·µ¢}‚Åø·µó·µ¢‚Çå‚ÇÅ

Goal: Learn f: XT ‚Üí YT using labeled DS and unlabeled DT
```

**Domain Discrepancy Measures**:
- Maximum Mean Discrepancy (MMD)
- Correlation Alignment (CORAL)
- Adversarial domain adaptation

### 11. Attention Mechanisms

#### 11.1 Self-Attention

**Scaled Dot-Product Attention**:
```
Attention(Q, K, V) = softmax(QK·µÄ/‚àöd_k)V

Where:
- Q: queries matrix
- K: keys matrix
- V: values matrix
- d_k: dimension of keys
```

**Multi-Head Attention**:
```
MultiHead(Q, K, V) = Concat(head‚ÇÅ, ..., head‚Çï)W·µí

head_i = Attention(QW·µ¢Q, KW·µ¢K, VW·µ¢V)
```

#### 11.2 Vision Transformer (ViT)

**Patch Embedding**:
```
Input image: H √ó W √ó C
Patch size: P √ó P
Number of patches: N = HW/P¬≤
Patch embedding: N √ó (P¬≤C)
```

**Position Encoding**:
```
Add learnable position embeddings to patch embeddings
```

### 12. Generative Models

#### 12.1 Variational Autoencoders (VAE)

**Encoder**: q_œÜ(z|x) ‚âà p(z|x)
**Decoder**: p_Œ∏(x|z)

**ELBO (Evidence Lower Bound)**:
```
log p(x) ‚â• E_{q_œÜ(z|x)}[log p_Œ∏(x|z)] - KL(q_œÜ(z|x) || p(z))
```

**Reparameterization Trick**:
```
z = Œº + œÉ ‚äô Œµ, where Œµ ~ N(0, I)
```

#### 12.2 Generative Adversarial Networks (GANs)

**Minimax Game**:
```
min max V(D, G) = E_{x~p_data}[log D(x)] + E_{z~p_z}[log(1 - D(G(z)))]
 G   D
```

**Training Algorithm**:
1. Update Discriminator: maximize V(D, G)
2. Update Generator: minimize V(D, G)

---

This deep learning theory provides the mathematical foundation for understanding the neural network implementations in the camera algorithms project.
